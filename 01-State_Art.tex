\chapter{State of the Art}
\label{ch:stateoftheart}

% \cite{flax2020github}

When dealing with humanoid robotics, the intricacy of feature engineering it is often time-consuming, hardly flexible and might bring to sub-optimal assets. Furthermore, the complexity given by the realistic multibody dynamics involving friction, contacts, elasticity and gravity might be restricting when there is the need for the robot to adapt to new scenarios.

In recent years, the field of robotics has been propelled by the combination of artificial intelligence and mechanical design. Such fusion pushed the frontiers of applications that brought to an inexorable increase of the need to face progressively harder challenges and tasks. However, it is the application of deep reinforcement learning that has truly unlocked their potential, propelling them into realms of unprecedented intelligence, adaptability and interaction. 

Picture a robot capable of physically interacting with objects, learning complex manipulation skills that mimic human dexterity, and effortlessly adapting to novel scenarios without explicit programming. These visions are rapidly becoming a reality, thanks to the convergence of deep RL and humanoid robot codesign.

