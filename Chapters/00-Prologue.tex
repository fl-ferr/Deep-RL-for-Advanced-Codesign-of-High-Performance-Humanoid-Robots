\chapter*{Prologue}
\label{chp:00-Prologue}

\section*{Motivation and Objectives}

Robots are often associated with their capability to move and interact with the surroundings, navigate through complex environments, pick up objects, and perform various tasks in a wide range of applications \citep{article,zeng_robotic_2022}, nevertheless, this goal has not yet been achieved. The field of robotics has been rapidly evolving in recent years, with robots becoming increasingly aware of their surroundings and behaving accordingly, eventually becoming more capable of performing complex tasks. This process involves the development of algorithms and hardware to enable robots to perform tasks autonomously and receive and process information coming from the environment thanks to a large set of sensors. Picture a robot capable of physically interacting with objects, learning complex and robust human-like walking, and effortlessly adapting to novel scenarios without explicit design for those new tasks.
The most common approach to achieve this is to use a combination of sensors, algorithms, and control strategies to enable the robot to perceive its movements and make decisions based on that data \citep{lara_embodied_2018, vaisi_review_2022}, thus this requires extensive knowledge of the robot's dynamics and the environment in which it operates, which is often difficult to obtain especially in the case of robots with a high number of degrees of freedom (\ac{DoF}).

When dealing with humanoid robotics, the complexity of manually designing and fine-tuning specific features is often time-consuming, hardly flexible, and might lead to sub-optimal assets. Furthermore, when designing model-based controllers, the complexity given by the realistic multibody dynamics involving friction, contacts, elasticity, and gravity requires several approximations that might lead to poor results when ported onto the real robotic platform. From here, comes the need for an alternative approach in which there is no need to explicitly formulate the dynamics of the robot, but rather to let the robot learn how to move and interact with the environment by itself using the available sensors and actuators. That is why the application of deep reinforcement learning (\ac{RL}) to robotics has been gaining momentum in recent years \citep{golroudbari_recent_2023,li_reinforcement_2021}.

For what concerns robot design, the morphological and physical properties are sometimes overlooked during the development of these control systems, as mainly provided by the manufacturer, treating the robot structure as an immutable factor that should be exploited by the controller. Conversely, during the mechanical design of the robot's physical structure, factors such as the intended task and the specific mode of execution may not be adequately considered. The lack of alignment between the robot's hardware and control architectures can potentially lead to suboptimal performance metrics, including speed, accuracy, and robustness \citep{sorokin_designing_2023}.

Opportunities for improvement can be found then optimizing hardware and control together to achieve the foreseen level of performance. With this methodology, the robot's body is not just a passive component but an active part of the control system loop, and the control system is not just a set of algorithms but a key parameter in the robot morphology design. This concept is commonly referred to as \textit{codesign}. This comprehensive approach is pivotal because it consists of optimizing the inherent characteristics of the robot's physical design in conjunction with the hardware. This optimization enhances efficiency and effectiveness for a predetermined set of tasks, ensuring a synergistic alignment between the physical attributes and the control mechanisms.
. Previous attempts at codesign for robotics have been made using mainly gradient-free optimization methods, such as genetic algorithms in bi-level optimizations \citep{sartore_optimization_2022,fadini_simulation_2022}, while the use of deep reinforcement learning, which until now has been exclusively associated to control, has been bounded to environments with limited complexity, such as a 2D plane \citep{ha_reinforcement_2019}, optimizing simplified hardware with a limited number of links \citep{chen_hardware_2020} or avoiding retraining the neural network (\ac{NN})-model at each optimizer iteration \citep{bjelonic_learning-based_2023}, potentially leading to sub-optimal resulting parameters propagating throughout the whole design process. Although taking into account the whole-body dynamics of a humanoid robot can result in a more realistic and accurate model, it requires high computational power and time as seen when designing control architectures \citep{ramuzat_benchmarking_2022}, making it difficult to use in a codesign loop. That is why it has not been widely investigated in the field of codesign for robotics. However, these computations are by nature highly parallelizable as composed of a large number of matrix operations, which could be solved in an efficient and fast way with parallel computing \citep{gyawali_comparative_2023, tuma_2023}, are involved and the use of specialized hardware components for computation that is characterized by parallel architectures, such as \ac{GPU} and \ac{TPU} could be exploited, significantly speeding up complex and resource-extensive computations, usually referred to as \textit{hardware acceleration}. Moreover, when training a \ac{RL} agent, the high parallelization can not only help to gain noticeably more experience, as multiple copies of the same agent can be run at the same time, each one interacting with the environment and collecting data, but also to speed up the \textit{neural network}s (\ac{NN}) training process, as just as dynamics computations, it involves a large number of matrix operations that can be parallelized \citep{pandey_transformational_2022,gyawali_comparative_2023}.

In light of the limitations identified in previous codesign efforts, which often operated within simplified environments and models, this work aims to explore a novel approach, trying to overcome the challenges of codesign by exploiting the capabilities of modern hardware-accelerated architectures as a support of a codesign loop combining genetic algorithms and deep reinforcement learning.

\section*{Contributions}

The main contributions of this work can be summarized as follows:

\begin{enumerate}
    \item An in-depth analysis and enhancement of a differentiable physics simulator, with a focus on contact dynamics and forward dynamics computation.
    \item A formulation for the forward dynamics of a rigid multibody system considering motor dynamics with the use of recursive propagation methods and the related implementation in a hardware-accelerated simulator.
    \item A codesign framework for humanoid robots, that exploits the potential of deep reinforcement learning and genetic algorithms, supported by hardware acceleration.
    \item A set of experiments that demonstrate the effectiveness and the limitations of the proposed framework.
\end{enumerate}


\section*{Outline}

The present work is organized as follows:

\begin{description}

    \item{\hyperref[part:background]{Part I: Background}}

          \begin{description}
              \item[{\hyperref[chp:back_RBDynamics]{In the first chapter}}] The mathematical foundations of rigid body dynamics are presented, along with the notation and the conventions that are used throughout the work.
              \item[{\hyperref[chp:back_PhysicsSimulators]{In the second chapter}}] The current panorama of physics simulators is presented, with a focus on the differentiable simulators and in particular on the one exploited and modified for the purpose of this work.
              \item [{\hyperref[chp:back_RLGA]{In the third chapter}}] The fundamentals of reinforcement learning and evolutionary algorithms are presented, with a focus on the algorithms and the techniques that are exploited in the codesign loop.
          \end{description}

    \item{\hyperref[part:contributions]{Part II: Contributions}}

          \begin{description}
              \item[{\hyperref[chp:contrib_ABA]{In the fourth chapter}}] The formulation and implementation of a recursive rigid body dynamics algorithm that takes into account motor dynamics is presented, along with the details regarding its implementation in a hardware-accelerated simulator.
              \item[{\hyperref[chp:contrib_CodesignRL]{In the fifth chapter}}] The codesign framework exploiting deep reinforcement learning and evolutionary algorithms is presented, furthermore the methods and the main challenges of the implementation of a complete codesign framework that exploits the potential of reinforcement learning and genetic algorithms are discussed.
              \item[{\hyperref[chp:contrib_ResultsDiscussion]{In the sixth chapter}}] The results of the experiments are presented and discussed, with a focus on the analysis of the performance of the different algorithms and the comparison between the different approaches.
              \item[{\hyperref[chp:contrib_Conclusions]{In the last chapter}}] The conclusions of the present work are drawn, with an eye on future developments and the potential applications of the proposed framework.
          \end{description}
\end{description}
