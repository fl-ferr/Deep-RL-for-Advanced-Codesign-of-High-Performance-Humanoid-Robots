\chapter*{Prologue}
\label{chp:00-Prologue}

\section*{Motivation and Objectives}

Robots are often associated with their  \CarlottaSays{\st{capacity} capability} to move and interact with the environment, navigating through complex \CarlottaSays{\st{environments} repetition }, picking up objects, and performing various tasks in a wide range of applications \citep{article,zeng_robotic_2022} \CarlottaSays{but this goal has not yet been achieved}. The field of robotics has been rapidly evolving in recent years, with robots becoming increasingly aware of their surroundings and behaving accordingly, eventually becoming more capable of performing complex tasks. This process, \CarlottaSays{\st{known as motion intelligence}}, involves the development of algorithms \CarlottaSays{and hardware} \CarlottaSays{\st{that} to} enable robots to perform tasks autonomously and receive and process information coming from the environment \CarlottaSays{thanks to various sensors} \CarlottaSays{\st{and most of all from their own body}}. Picture a robot capable of physically interacting with objects, learning complex and robust human-like walking, and effortlessly adapting to novel scenarios without explicit design for those new tasks.
The most common approach to achieve this is to use a combination of sensors, algorithms, and control strategies to enable the robot to perceive its movements and make decisions based on that data \citep{lara_embodied_2018, vaisi_review_2022}, thus this requires extensive knowledge of the robot's dynamics and the environment in which it operates, which is often difficult to obtain especially in the case of robots with a high number of degrees of freedom (\ac{DoF}).

\CarlottaSays{The problem here is that you mix control, design and do not talk about codeisng, better to introduce one concept at the time} 

When dealing with humanoid robotics, the complexity of manually designing and fine-tuning specific features is often time-consuming, hardly flexible, and might lead to sub-optimal assets. Furthermore, \CarlottaSays{when designing model based controller,} the complexity given by the realistic multibody dynamics involving friction, contacts, elasticity, and gravity \CarlottaSays{requires different approximations that } might lead to poor results \CarlottaSays{when ported on the real robotic platform \st{when there is a need for the robot to adapt to new scenarios}}. \CarlottaSays{\st{This combination of factors makes it challenging to design a robot that can perform a wide range of tasks in a variety of environments and using classical optimization approaches might become infeasible}}. From here, comes the need for an alternative approach in which there is no need to explicitly formulate the dynamics of the robot, but rather to let the robot learn how to move and interact with the environment by itself using the available sensors and actuators. That is why the application of deep reinforcement learning (\ac{RL}) to robotics has been gaining momentum in recent years \citep{golroudbari_recent_2023,li_reinforcement_2021}.

\CarlottaSays{For what concerned the robot design, }the morphological and physical properties of a robot are sometimes overlooked during the development of these control systems, as mainly provided by the manufacturer, and \CarlottaSays{and the robot design is treated as something immutable and given, the controller should exploit that.} \CarlottaSays{\st{the research is focused on the development of the robot's software}}. Conversely, during the mechanical design of the robot's physical structure, factors such as the intended task and the specific mode of execution may not be adequately considered. The lack of alignment between the robot's hardware and \CarlottaSays{control architecture \st{software development}} can potentially lead to suboptimal \CarlottaSays{\st{designs} performances} \CarlottaSays{\st{that hinder the final performance metrics, including speed, accuracy, and robustness}}. \CarlottaSays{Here some examples with literature references, can help out}

Opportunities for improvement can be found \CarlottaSays{then did not get why you put when?} optimizing hardware and control together to achieve the foreseen level of performance. With this methodology, the robot's body is not just a passive component but an active part of the control system loop, and the control system is not just a set of algorithms but a key parameter in the robot morphology design. This concept is commonly referred to as \textit{codesign}. \CarlottaSays{\st{This holistic approach can be crucial because it involves leveraging the inherent characteristics of the robot's physical design to optimize its efficiency and effectiveness for a set of given tasks} leveraging is wrong, the physical attribute are optimized together with the hardware, not exploited by the control. If you want you can improve it and leave something similar}. Previous attempts at codesign for robotics have been made using mainly gradient-free optimization methods, such as genetic algorithms \CarlottaSays{For doing what ? there is a bilevel optimization in this work, one is applied to humanoid robots, other to quadropter (if i am not wrong), one optimize the hardware with respect to energy expenditure. Which are the problems in this work ?  you should underline this, to make clear to the reader what is your contirbution} \citep{sartore_optimization_2022,fadini_simulation_2022}, while the use of deep reinforcement learning \CarlottaSays{How is RL applied to codesing ? till now It is associated only to control} has been bounded to environments with limited complexity, such as a 2D plane \citep{ha_reinforcement_2019}, optimizing simplified hardware with a limited number of links \citep{chen_hardware_2020} or avoiding retraining the neural network (\ac{NN})-model at each optimizer iteration \citep{bjelonic_learning-based_2023}, potentially leading to sub-optimal resulting parameters propagating throughout the whole design process. Though taking into account the whole-body dynamics of a humanoid robot can result in a more realistic and accurate model, it requires high computational power and time \CarlottaSays{The paper is referred to whole body controller, we are talking to co-design, you should underline this something like "as seen when designing control architecture". Also there is a big difference: control architecture should run online while hardware optimization is performed offline, the concept of "long time" is different} \citep{ramuzat_benchmarking_2022}, making it difficult to use in a codesign loop. That is why it has not been widely investigated in the field of codesign for robotics. \CarlottaSays{I would revert, saying something like: is time consuming difficult to be applied to codesing loops where the search space is huge, in recent years, the development of hardware accelerated simulators \cite{TODO}, bla bla bla } However, these computations are by nature highly parallelizable as \CarlottaSays{composed by } a large number of matrix operations, \CarlottaSays{\st{easily} remember the pain you had in solving this :)} solvable with parallel computing \citep{gyawali_comparative_2023, tuma_2023}, are involved and the use of specialized hardware components for computation that is characterized by parallel architectures, such as \ac{GPU} and \ac{TPU} could be exploited, significantly speeding up complex and resource-extensive computations, usually referred to as \textit{hardware acceleration}. Moreover, when training a \ac{RL} agent, the high parallelization can not only help to gain noticeably more experience, as multiple copies of the same agent can be run at the same time, each one interacting with the environment and collecting data, but also to speed up the \textit{neural network}s (\ac{NN}) training process, as just as dynamics computations, it involves a large number of matrix operations that can be parallelized \citep{pandey_transformational_2022,gyawali_comparative_2023}.

In light of the limitations identified in previous codesign efforts, which often operated within simplified environments and models, this work aims to explore a novel approach, trying to overcome the challenges of codesign by exploiting the capabilities of modern hardware-accelerated architectures as a support of a codesign loop combining genetic algorithms and deep reinforcement learning.

\section*{Contributions}

The main contributions of this work can be summarized as follows:

\begin{enumerate}
    \item An in-depth analysis and enhancement of a differentiable physics simulator, with a focus on contact dynamics and forward dynamics computation.
    \item A motor dynamics conditioned formulation for the forward dynamics of a rigid multibody system with the use of recursive propagation methods \CarlottaSays{Formulation of forward dynmic of a rigid multi body system considering the motor dynamics bla bla bla and the related implementation in  bla bla bla }.
    \item A co-optimization \CarlottaSays{why not codesing ? e.g. codesing framework for humanoid robtos} framework for the codesign of humanoid robots, that exploits the potential of deep reinforcement learning and genetic algorithms, supported by hardware acceleration.
    \item A set of experiments that demonstrate the effectiveness and the limitations of the proposed framework.
\end{enumerate}


\subsection*{Outline}

The present work is organized as follows:

\begin{description}

    \item{\hyperref[part:background]{Part I: Background}}

          \begin{description}
              \item[{\hyperref[chp:back_RBDynamics]{In the first chapter}}] The mathematical foundations of rigid body dynamics are presented, along with the notation and the conventions that are used throughout the work.
              \item[{\hyperref[chp:back_PhysicsSimulators]{In the second chapter}}] The current panorama of physics simulators is presented, with a focus on the differentiable simulators and in particular on the one exploited and modified for the purpose of this work.
              \item [{\hyperref[chp:back_RLGA]{In the third chapter}}] The fundamentals of reinforcement learning and evolutionary algorithms are presented, with a focus on the algorithms and the techniques that are exploited in the codesign loop.
          \end{description}

    \item{\hyperref[part:contributions]{Part II: Contributions}}

          \begin{description}
              \item[{\hyperref[chp:contrib_ABA]{In the fourth chapter}}] The \CarlottaSays{formulation and } implementation of a recursive rigid body dynamics algorithm that takes into account motor dynamics is presented, along with the details regarding its implementation in a hardware-accelerated simulator.
              \item[{\hyperref[chp:contrib_CodesignRL]{In the fifth chapter}}] The state of the art \CarlottaSays{Why the state of the art is in the contribution ?, I would expect here to have the presentation of the codesing framework} in the field of codesign and reinforcement learning is presented, furthermore the methods and the main challenges of the implementation of a complete codesign framework that exploits the potential of reinforcement learning and genetic algorithms are discussed.
              \item[{\hyperref[chp:contrib_ResultsDiscussion]{In the sixth chapter}}] The results of the experiments are presented and discussed, with a focus on the analysis of the performance of the different algorithms and the comparison between the different approaches.
              \item[{\hyperref[chp:contrib_Conclusions]{In the last chapter}}] The conclusions of the present work are drawn, with an eye on future developments and the potential applications of the proposed framework.
          \end{description}
\end{description}
