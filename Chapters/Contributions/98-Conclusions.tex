\chapter{Conclusions and Future Work}
\label{chp:contrib_Conclusions}

The process of implementing a codesign loop has required several intermediate steps. First, the review and adaptation of an already established recursive algorithm for the forward dynamics computation, which allowed to study the effect of the motor dynamics in robotics simulations, then the application of deep reinforcement learning to two main problems, a simple balancing task with a cartpole system, which required the development of an interface between a hardware accelerated simulator like \jaxsim and a reinforcement learning baseline implementation, and a more complex task of locomotion with a humanoid robot, which will represent the major challenge for the future development of the framework. Finally, the implementation of an evolutionary algorithm capable of exploiting data coming from reinforcement learning in order to optimize the motor parameters of a robot, which allowed to study the effects of the motor design on the robot's performance.

Although the modified \ac{ABA} algorithm allows for a more realistic forward dynamics computation when there is the need to take into account the motor dynamics, some hypotheses are still made in the derivation of the algorithm. In particular, future versions of the algorithm might take into account the effect of a non-negligible transmission inertia. Furthermore, eliminating the assumption of equal motion subspace for the motor and the link would allow for the computation of more complex kinematic chains involving, for example, internal kinematic loops.

The results obtained with the \ac{RL} framework show that the proposed approach is effective in solving the tasks considered in this work. However, future versions of \jaxsim might include a more effective and accurate contact model, perhaps exploiting the differentiability of \jax, which has not been extensively studied yet. Moreover, the addition of a more accurate contact model and the development of an integrated visualizer would ease its use as a reinforcement learning playground in combination with the emerging differentiable physics engines.
The framework of \jax could be also exploited to have an open-source version of Adversarial Motion Prior, which exploits the differentiability to easily adapt learned policies to new robots. This would allow for a more effective transfer of learning between different robots, which is a crucial aspect in the development of robotic systems.

Finally, the results obtained with the robot codesign process show that the proposed approach is effective in finding a motor combination that is effective in maximizing the reward. However, the results obtained with the genetic algorithm are limited to a discrete motor parameter set. In the future, supposing to have an unlimited choice for motor design, the codesign loop might take into account continuous search spaces for the motor parameters, which would allow for more effective optimization. Moreover, the codesign loop might be extended to include the design of the robot morphology, such as the link lengths and density, enabling the algorithm to find the optimal robot design for a given task also from a geometrical point of view.