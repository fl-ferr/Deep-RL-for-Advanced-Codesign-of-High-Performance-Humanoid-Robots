\chapter*{Epilogue}
\label{chp:99-Epilogue}

This work presented a novel framework based on the combination of reinforcement learning and evolutionary algorithms for the codesign humanoid robots supported by the most recent advances in the field of hardware acceleration. In particular, it answers the research question:

\begin{quote}
    \textit{
        Can robot morphology be optimized together with control architectures respect to a given task?}
\end{quote}

addressing the problem of finding the optimal motor parameters for the locomotion task.
In order to answer this question, the work presented a novel framework that combines reinforcement learning and evolutionary algorithms to optimize the motor parameters of a humanoid robot for the locomotion task. In particular, in \cref{part:background} the work presented the background knowledge required to understand the work, starting from the notation and the preliminaries of rigid multibody dynamics, the description of the \ac{ABA} algorithm, which is the basis for the forward dynamics computation in the framework, and then moving to an overview of the current state of the art in the field of hardware accelerated simulators, with a focus on the emerging role of \jax in the field of deep learning and robotics. Finally, the theorical background of deep reinforcement learning and evolutionary algorithms was presented, introducing the reader to the main concepts of the two fields and the most common algorithms used in the literature. In \cref{part:contributions}, the work presented the two main contribution of the thesis. First, the work presented the implementation of a modified version of the \ac{ABA} algorithm that allows for a more realistic forward dynamics computation when there is the need to take into account the motor dynamics, which served as an additional feature for the hardware accelerated \jaxsim simulator, allowing to consider the effect of rotors in the robot joints, and second, the implementation of a codesign loop which creates a synergy between reinforcement learning and evolutionary algorithms in order to guide the optimization of the motor parameters of a humanoid robot for the locomotion task.

This work addressed therefore the problem of the lack of a simulation environment that allows for a computation of the forward dynamics that takes into account the presence of motors mounted on the joints of the robot, allowing for a potentially smaller gap between the simulation and the real world application. The framework was tested on a simple, yet easily scalable environment, and the results showed that the developed architecture is able to find a set of motor parameters that allows for a better reward in the reinforcement learning scenario.
The proposed codesign could be propelled by the recent advances in the field of hardware acceleration and the development of differentiable physics engines, which is crucial for the development of a more extensive co-optimization architecture.